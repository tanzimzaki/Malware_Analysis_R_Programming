# Name: Tanzim Zaki Saklayen


--------------------------------------------------------------------------------------------------------------------------------------------

# Installation of the training and test datasets
  
install.packages(c("tidyverse","GGally","caret","corrplot","car"))
install.packages("caret")
install.packages("GGally")
install.packages("corrplot")
install.packages("car")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("tidyverse")
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("pROC") 


library(tidyverse)  # For ggplot2
library(GGally)  # For scatter plot matrix
library(caret)  # Classification and Regression Training package
library(corrplot)  # For visualizing correlation matrix
library(car)  # For the VIF function
library(rpart) # Recursive Partitioning And Regression Trees
library(rpart.plot) # For plotting trees
library(pROC) # For AUC



# Supervised learning models that is selected randomly with the given Student ID 

set.seed(10520140)
models.list1 <- c("Logistic Ridge Regression",
                  "Logistic LASSO Regression",
                  "Logistic Elastic-Net Regression")

models.list2 <- c("Classification Tree",
                  "Bagging Tree",
                  "Random Forest")

myModels <- c("Binary Logistic Regression",
              sample(models.list1,size=1),
              sample(models.list2,size=1))

myModels %>% data.frame    # the line will generate the appropriate 3 models required to work on but please make sure to run 'models.list1', 'models.list2', and 'myModels' before initiating the line   
  
----------------------------------------------------------------------------------------------------------------------------------------
  
# Part 1
  
datafr <- read.csv("C:/users/pc/Downloads/MLDATASET_PartiallyCleaned.csv",header=TRUE,stringsAsFactors=TRUE) 


datafr$How.Many.Times.File.Seen[datafr$How.Many.Times.File.Seen == 65535] <- NA # Restoring all values equal to 65535 with NA

datafr$Threads.Started[datafr$Threads.Started > 5] <- 5 # Restoring all values greater than 5 that is equal to  5

datafr$Threads.Started <- as.factor(datafr$Threads.Started) # Convert 'Threads.Started' to a factor 

datafr$Characters.in.URL <- log(datafr$Characters.in.URL) # Transforming Log Characters in URL 

datafr <- na.omit(datafr)

write.csv(datafr,"MLDATASET.cleaned.CSV")


set.seed(10520140) # Initiating Random Seed with the Student ID number

trainRowNum <- createDataPartition(datafr$Actually.Malicious, #The outcome variable
                                   #proportion of data to form the training set
                                   p=0.30,
                                   #Don't store the result in a list
                                   list=FALSE)


trainData <- datafr[trainRowNum,]  # Development of the training dataset
write.csv(datafr,"train.cleaned.CSV")
testData <- datafr[-trainRowNum,] # Development of the test dataset
write.csv(datafr,"test.cleaned.CSV")
View(trainData)
View(testData)

------------------------------------------------------------------------------
  
# Part 2: 3 models - Binary Logistic Regression, Logistic Elastic-Net Regression, and Classification Tree
  
# Model 1: Binary logistic regression
mod.A_mal.lg <- glm(Actually.Malicious~.-Sample.ID-Initial.Statistical.Analysis, family="binomial", data=trainData)

summary(mod.A_mal.lg) 


pred.prob <- predict(mod.A_mal.lg,new=testData,type='response') # Probability of Actually.Malicious on the test data
pred.class <- ifelse(pred.prob>0.5,"YES","NO") #Allocation to the assigned class

# Confusion matrix with establishing of "Yes" and "No"
cf.lg <- table(pred.class %>% as.factor %>% relevel(ref="YES"),testData$Actually.Malicious %>% relevel(ref="YES"))

prop <- prop.table(cf.lg,2);prop %>% round(digit=3) # Proportions by columns


confusionMatrix(cf.lg) # Overview summary of confusion matrix

prop <- prop.table(cf.lg, 2); prop %>% round(digit=3)*100 #Proportions by columns

specificity <- prop[1,1] #specificity
sensitivity <- prop[2,2] #sensitivity

accuracy <- sum(diag(cf.lg)) / sum(cf.lg)
c(Spec=specificity, Sens=sensitivity, Acc=accuracy) %>% round(digits = 4)*100



# Model 2: Logistic Elastic-Net Regression
alphas <- seq(0.1,0.9,by=0.1); alphas # A sequence of alpha values to test
lambdas <- 10^seq(-3,3,length=50); lambdas #A sequence 50 lambda values 
set.seed(10520140) # Initiating Random Seed with the Student ID number 

mod.A_mal.elnet <- train(Actually.Malicious~.-Sample.ID-Initial.Statistical.Analysis, #Formula
                         data = trainData, #Training data
                         method = "glmnet", #Penalized regression modeling
                         #Set the pre-process to c("center", "scale") to standardize data
                         preProcess = NULL,
                         #Perform 10-fold CV, 5 times over.
                         trControl = trainControl("repeatedcv",
                                                  number = 10,
                                                  repeats = 5),
                         tuneGrid = expand.grid(alpha = alphas, #Elastic-Net regression
                                                lambda = lambdas))

mod.A_mal.elnet$bestTune #Optimal lambda value


coef(mod.A_mal.elnet$finalModel, mod.A_mal.elnet$bestTune$lambda) # Model coefficients


pred.class.elnet <- predict(mod.A_mal.elnet,new=testData) #predicted classes of actual malware on the test data



cf.elnet <- table(pred.class.elnet %>% relevel(ref="YES"),    #Confusion matrix with re-ordering of "Yes" and "No" responses 
                  testData$Actually.Malicious %>% relevel(ref="YES"))


prop <- prop.table(cf.elnet,2); prop %>% round(digit=3) #Proportions by columns  
  
  
confusionMatrix(cf.elnet) #Summary of confusion matrix


prop <- prop.table(cf.elnet,2); prop %>% round(digit=3) #Proportions by columns 

specificity <- prop[1,1] # specificity
sensitivity <- prop[2,2] # sensitivity

accuracy <- sum(diag(cf.elnet)) / sum(cf.elnet)  # Accuracy
c(Spec=specificity, Sens=sensitivity, Acc=accuracy) %>% round(digits = 4)*100



# Model 3: Classification  

rtree <- rpart(Actually.Malicious~., #Formula
               data=select(trainData, -c(Sample.ID, Initial.Statistical.Analysis)), method = "class")

pred.prob <- predict(rtree, newdata=testData, type="prob") %>% data.frame  # Test Set Code
pred.class <- predict(rtree, newdata=testData, type="class")

rtree # Generate the result


pred.class.tree <- predict(rtree, newdata = testData, type = "class") # Predicted classes of Actually.Malicious on the test data 


confusionMatrix(cf.tree)


confusionMatrix(ifelse(testData$Initial.Statistical.Analysis %in% c("Incorrectly Identified as Clean",
                                                                    "Correctly Identified as Clean"),
                       "NO", "YES") %>% as.factor()
                %>% relevel(ref="YES"),
                testData$Actually.Malicious %>% relevel(ref="YES"))       # Generation of identification of 'correctly' and 'incorrectly' cleaned Malware data


prop <- prop.table(cf.tree,2); prop %>% round(digit=3)*100 #Proportions by columns

specificity <- prop[1,1] # specificity
sensitivity <- prop[2,2] # sensitivity

accuracy <- sum(diag(cf.tree)) / sum(cf.tree)  # Accuracy
c(Spec=specificity, Sens=sensitivity, Acc=accuracy) %>% round(digits = 4)*100

cf.tree.pr <- train(Actually.Malicious~., data = trainData, method = "rpart",
                  trControl = trainControl("cv", number = 10), # 10-fold CV
                  tuneLength = 15) # Number of cp values to test
#Plot the CV result
plot(cf.tree.pr)


------------------------------------------------------------------------------------------------------------

